#Thinking1	新零售中的“人、货、场”分别指的是什么？#			
答：
人货场其实是指统计维度，对人货场的三维度分析进行探索 围绕用户，围绕商品，围绕渠道

人：个人理解是对用户做用户画像，在一些静态属性（比如年龄，性别，婚姻状况等）和 隐藏属性（如用户兴趣，偏好，收入等）之间，得出对公司产品有价值的用户，或一些可以拉拢的潜在用户。得出目标人群。分析潜在价值。

货：一般指对于本公司产品的分析，通过产品分析了解产品的浏览量、点击量、订单、入篮量、购买用户数等信息，从而帮助企业了解不同商品的用户关注度、购买力等，为产品生命周期分析、产品推广策略提供数据支持。
并在此基础上进行营销策略上的优化。

场：指的是产品进行输出消费的场所，一般情况下分为线上和线下。
对于线下而言，可以对店铺的选址，顾客的消费体验等各个角度进行分析，优化销售策略。

对于线上而言，应用或网站的界面，检索，推荐等各种功能，广告，等各种流量各种维度进行分析。优化产品输出能力。





# Thinking2	AIPL与传统的品牌资产评估有何区别？ #	

答：在AIPL模型之前，“人群资产”是很难量化，是个笼统的概念。
AIPL模型，把品牌在电商中的人群资产定量化的运营模型。将人群分为认知，兴趣，购买，忠诚4个部分。这样每个部分能够准确的预测出来，这样人群资产也就量化了。



		
# Thinking3	请列举一例生活工作中存在的帕累托法则 #			

答：其实有个很明显的例子就是社会人群财富占比，可能前5%的人掌握了90%以上的社会财富。而剩下的95%的人才掌握了10%的社会财富。这个可能比2/8 的比例更大。也更形象吧。。




# Thinking4	请简述GBDT与XGBoost的区别？ #

答：
1.传统GBDT以CART作为基分类器，xgboost还支持线性分类器，这个时候xgboost相当于带L1和L2正则化项的logistic  或  linear 问题。

2.传统GBDT在优化时只用到一阶导数信息，xgboost则对代价函数进行了二阶泰勒展开，同时用到了一阶和二阶导数。

3.XGBoost加入了正则项来控制模型的复杂度，有利于防止过拟合，从而提高模型的泛化能力

4.xgboost借鉴了随机森林的做法，支持列抽样，不仅能降低过拟合，还能减少计算，这也是xgboost异于传统gbdt的一个特性。

5.对缺失值的处理。对于特征的值有缺失的样本，xgboost可以自动学习出它的分裂方向。



# Thinking5	如何处理神经网络中的过拟合问题？ #			
答：
1.可以选择更完善的训练集信息。数据集应涵盖模型应处理的所有输入范围。
2.使用dropout， “dropout rate”是被清零的特征的一部分。通常设置在0.2到0.5之间。
3.正则化，神经网络中损失函数，可以增加一个额外的正则项（L1或L2）正则项看做是损失函数的惩罚项
4.网络结构，调整网络结构，通常使用筒形或漏斗形。
5.减少入参个数，在深度学习中，模型中的可学习参数的个数称为模型的容量。参数越多，模型就拥有越大的记忆容量。减小网络容量，即减少参数的个数，即对层数和每层的单元个数进行处理。


